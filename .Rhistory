?stat_density
g + geom_histogram(aes(x=dist.3d6), binwidth=.25)
g + geom_histogram(aes(x=dist.3d6), binwidth=1)
g + geom_histogram(aes(x=dist.3d6), binwidth=1, y=..density..)
g + geom_histogram(aes(x=dist.3d6, y=..density..), binwidth=1)
g <- ggplot(df.3d6, aes(x=dist.3d6))
g + geom_histogram(aes(y=..density..), binwidth=1)
geom_density()
g + geom_histogram(aes(y=..density..), binwidth=1) +
geom_density()
?dnorm
g + geom_histogram(aes(y=..density..), binwidth=1) +
stat_function(fun=dnorm, args=list(mean=mean(df.3d6$dist.3d6),
sd=sd(df.3d6$dist.3d6)))
g + geom_histogram(aes(y=..density..), binwidth=.5) +
stat_function(fun=dnorm, args=list(mean=mean(df.3d6$dist.3d6),
sd=sd(df.3d6$dist.3d6)))
g + geom_histogram(aes(y=..density..), binwidth=1) +
stat_function(fun=dnorm, args=list(mean=mean(df.3d6$dist.3d6),
sd=sd(df.3d6$dist.3d6)))
dice.pr(1, 1, 20, 20)
mean(df.3d6$dist.3d6)
dice.pr
dice.pr(1, 3, 10, 20)
dice.pr(1, 1, 10, 20)
dice.pr(1, 1, 15, 20)
dice.pr(1, 3, 15, 20)
dice.pr(1, 4, 15, 20)
dice.pr(1, 5, 15, 20)
dice.pr(1, 1, 5, 20)
dice.pr(1, 1, 10, 20)
dice.pr(1, 1, 20, 20)
dice.pr(1, 1, 15, 20)
dice.pr(2, 3, 10, 20)
ndk(1,20)
ndk(1,20)
ndk(1,20)
ndk(1,20)
sample(1:52, 3)
sample(1:52, 3, replace=FALSE)
sample(1:52, 5, replace=FALSE)
source('~/code/RPG/kitt_dice.R', echo=TRUE)
dice.pr(3, 4, 10, 20)
dice.pr(1, 4, 10, 20)
dice.pr(1, 4, 15, 20)
dice.pr(1, 4, 15, 20)
dice.pr(1, 1, 15, 20)
dice.pr(1, 1, 10, 20)
dice.pr(1, 1, 15, 20)
dice.pr(1, 4, 10, 20)
?geom_histogram
2/54
1/20
library(xlsx)
url2 <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(url2, "ngap.xlsx")
source('~/code/coursera/gacd/quiz1.R', echo=TRUE)
?read.xlsx
?colIndex
dat <- read.xlsx("ngap.xlsx", startRow=18, endRow=23, colIndex=c(7:15))
dat <- read.xlsx("ngap.xlsx", sheetIndex=1,
startRow=18, endRow=23, colIndex=c(7:15))
ls()
dat <- read.xlsx("ngap.xlsx")
download.file(url2, "ngap.xlsx", method="curl")
get_wd()
wetwd()
getwd()
download.file(url2, "ngap.xlsx", method="curl", mode="wb")
download.file(url2, "ngap.xlsx", mode="wb")
dat <- read.xlsx("ngap.xlsx")
dat <- read.xlsx("ngap.xlsx", sheetIndex=1)
dat <- read.xlsx("ngap.xlsx", sheetIndex=1, startRow=18, endRow=23,
colIndex=c(7:15))
sum(dat$Zip*dat$Ext,na.rm=T)
url3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(url3, "rest.xml", mode="wb")
library(XML)
install.packages("XML")
tree <- xmlTreeParse(url3, useInternal=T)
library(XML)
tree <- xmlTreeParse(url3, useInternal=T)
tree <- xmlTreeParse(url3, useInternal=T, isURL=T)
tree <- xmlTreeParse("rest.xml", useInternal=T)
head(tree)
xmlRoot(tree)
xmlName(tree)
rnode <- xmlRoot(tree)
xmlName(root)
xmlName(rnode)
names(rnode)
rnode
xmlSApply(rnode, table(zipcode))
names(rnode)
names(rnode[row])
names(rnode["row"])
names(rnode)[1]
names(rnode)[1][1]
rnode[1][1]
xmlValue(rnode)
xmlChildren(rnode)
names(rnode[[1]])
names(rnode[[1]][["zipcode"]])
tgt <- rnode[[1]][["zipcode"]]
names(rnode[[1]])
names(rnode[[1]][["row"]])
tgt <- rnode[[1]][["row"]]
names(tgt[["zipcode"]])
xmlValue(tgt[["zipcode"]])
table(xmlSApply(tgt, function(x) xmlSApply(x, xmlValue)))
xmlSApply(tgt, function(x) xmlSApply(x, xmlValue))
xmlSApply(tgt[["zipcode"]], function(x) xmlSApply(x, xmlValue))
xmlSApply(tgt[["zipcode"]][["text"]], function(x) xmlSApply(x, xmlValue))
xmlSApply(tgt[["zipcode"]][["text"]], xmlValue())
xmlSApply(tgt[["zipcode"]][["text"]], function(x) xmlValue(x))
tgt
names(rnode)
names(rnode[[1]])
names(rnode[[1]][["row"]])
names(rnode[[1]]["row"])
names(rnode[[1]][["row"]])
xmlValue(tgt[[1]])
xmlValue(tgt[["zipcode"]])
tgt <- rnode[[1]][[1]]
tgt
tgt <- rnode[[1]][["row"]]
tgt
tgt <- rnode[[1]]
tgt
tgt <- rnode[[1]]
xmlValue(tgt[["zipcode"]])
names(tgt)
xmlValue(tgt[["row"]])
names(tgt[["row"]])
xmlSApply(tgt, xmlValue)
tgt <- rnode[[1]][["row"]]
xmlSApply(tgt, xmlValue)
tgt <- rnode[[1]][["zipcode"]]
xmlSApply(tgt, xmlValue)
names(tgt)
names(rnode)
names(rnode[["row"]])
names(rnode[["row"]]["row"])
names(rnode[["row"]][["row"]])
tgt <- rnode[["row"]]
xmlSApply(tgt, xmlValue)
xmlSApply(tgt, names)
xmlSApply(tgt, xmlValue)
xmlSApply(tgt, names)
tgt <- rnode[["row"]][[zipcode]]
xmlSApply(tgt, names)
tgt <- rnode[["row"]][[2]]
xmlSApply(tgt, names)
xmlSApply(tgt["zipcode"], names)
XMLNodeList(rnode)
xpathSApply(rnode)
nodes <- getNodeSet(rnode, "//row/row[@zipcode='21231'")
nodes <- getNodeSet(rnode, "//row/row[@zipcode='21231']")
nodes
lapply(nodes, function(x) xmlSApply(x, count))
lapply(nodes, function(x) xmlSApply(x))
lapply(nodes, xmlValue)
tgt <- rnode[["row"]][["row"]][["zipcode"]]
tgt
tgt <- rnode[["row"]][["row"]]
xmlSApply(tgt[["zipcode"]], xmlValue)
zips <- xmlSApply(tgt[["zipcode"]], xmlValue)
zips
zips <- xmlSApply(tgt, xmlValue)
zips
tgt <- rnode[["row"]]
zips <- xmlSApply(tgt, xmlValue)
zips
zips <- xmlSApply(tgt[[1]], xmlValue)
zips
zips <- xmlSApply(tgt[[1]][[2]], xmlValue)
zips
zips <- xmlApply(tgt[[1]][[2]], xmlValue)
zips
zips <- xmlApply(tgt[[2]][[2]], xmlValue)
zips
length(tgt)
nrow(target)
nrow(tgt)
count(tgt)
tgt
tgt[[]]
names(tgt)
length(names(tgt))
as.numeric(tgt[[1]][[2]])
as.numeric(tgt[[1]][[2]][[2]])
as.numeric(tgt[[1]][[2]])
tgt[[1]][[2]]
tgt[[1]][["zipcode"]]
xmlValue(tgt[[1]][[2]])
x <- data.frame()
for (i in 1:length(names(tgt))){
x[i] <- as.numeric(xmlValue(tgt[[i]][[2]]))
}
x <- data.frame()
for (i in 1:length(names(tgt))){
x <- rbind(x, as.numeric(xmlValue(tgt[[i]][[2]])))
}
table(x)
table(x)
url4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url4, mode="wt")
download.file(url4, destfile="survey.csv", mode="wt")
library(data.table)
DT <- fread("survey.csv")
times <- vector()
times[1] <- system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
x <- vector()
x[1] <- system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
install.packages("devtools")
install.packages("KernSmooth")
library(KernSmooth)
install.packages("RMySQL", type="source")
install.packages("RMySQL", type="source")
library(RMySQL)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
url4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdp <- read.csv(url4, skip=3, na.strings = ".. Not available.  ")
edu <- read.csv(url5)
gdp <- gdp[2:232,]
library(dplyr)
gdp <- rename(gdp, CountryCode=X, USD=US.dollars.)
gdp <- select(gdp, CountryCode, Ranking, Economy, USD)
x <- intersect(unique(levels(gdp$CountryCode)), unique(levels(edu$CountryCode)))
length(x)
gdp <- gdp[1:190,]
gdp <- mutate(gdp, ranknum=as.numeric(as.character(Ranking)))
arr <- arrange(gdp, desc(ranknum))
arr[13]
arr[13,]
names(arr)
head(arr)
head(gdp)
head(Edu)
head(edu)
gdp <- read.csv(url4, skip=3, na.strings = ".. Not available.  ")
edu <- read.csv(url5)
gdp <- gdp[2:232,]
names(gdp)
head(gdp)
names(edu)
gdp <- rename(gdp, CountryCode=X, USD=US.dollars.)
combined <- plyr::join(gdp, edu)
nrow(combined)
names(combined)
head(combined)
class(combined$ranking)
class(combined$Ranking)
combined <- mutate(combined, ranknum=as.numeric(as.character(Ranking)))
dt.c <- as.data.table(combined)
library(data.table)
dt.c <- as.data.table(combined)
dt.c[, lapply(ranknum, mean), by = "Income.Group"]
dt.c[, mean(ranknum), by = "Income.Group"]
dt.c[, mean(ranknum, na.rm=TRUE), by = "Income.Group"]
?quantile
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
dt.c[, gdp.fac:=cut2(ranknum, groups=5)]
?cut2
dt.c[, gdp.fac:=cut2(ranknum, g=5)]
dt.c[,ranknum]
dt.c[,gdp.fac]
table(dt.c$gdp.fac, dt.c$Income.Group)
url1 <- "https://s3.amazonaws.com/coursera-uploads/user-38001ad6a34ab90942e72fdd/973497/asst-3/0cef27c0a4a011e4bb36752a6296e791.txt"
?read.table
x1 <- read.table(url1, header=TRUE)
head(x1)
url2 <- "https://s3.amazonaws.com/coursera-uploads/user-327092b4f32d6c68057acee8/973497/asst-3/ab112010a4a411e49deb57f90ab7b90d.txt"
x2 <- read.table(url2, header=TRUE)
head(x2)
url3 <- "https://s3.amazonaws.com/coursera-uploads/user-07babd1eee70bc12be9a72a5/973497/asst-3/aeb29080a4a311e49e96f78ae7390c5d.txt"
x3 <- read.table(yrl3, header=TRUE)
x3 <- read.table(url3, header=TRUE)
head(x3)
url4 <- "https://s3.amazonaws.com/coursera-uploads/user-4cebba9b9c5a94f849e431d2/973497/asst-3/2044e9a0a49f11e494008734ab201470.txt"
x4 <- read.table(url4, header=TRUE)
head(x4)
mdy(10301978)
library(lubridate)
mdy(10301978)
dmy(10301978)
dmy("10301978")
dmy("10/30/1978")
dmy(10/30/1978)
library(airquality)
library(datasets
)
data(airquality)
library(ggplot2)
qplot(Windspeed, Ozone, data=airquality, facets=.~factor(Month))
data(movies)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
install.packages("ggthemes")
?variable
??variable
sessionInfo()
.libPaths()
install.packages("rattle")
rattle()
library(rattle)
rattle()
1e9
1e3
1e9
1 * e9
1*1e9
ch <- "B"
if(c == "b"|"B") print("b")
if(ch == "b"|"B") print("b")
ch
eval(ch)
if(eval(ch) == "b"|"B") print("b")
if(ch == "b"|"B") print("b")
ch == "b"
ch == "B"
ch == "b"|"B"
ls()
wd <- "C:/Users/Kitt/Documents/GitHub/noaastormdata"
if(getwd()!=wd) setwd(wd)
library(data.table)
library(R.utils)
library(ggplot2)
library(gridExtra)
library(dplyr)
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
fn <- "stormdata.csv"
if(!file.exists(fn)) download.file(url, fn, mode="wb")
if(!file.exists(fn)) bunzip2("stormdata.bz2", fn, remove=FALSE)
storm <- read.csv(fn)
dt1 <- data.table(storm)
rm(storm)
# unifTime converts all the weird time entries into a uniform time format
unifTime <- function(char.time){
if(nchar(char.time) > 4){
t <- substr(char.time, 0, 5)
} else if(nchar(char.time) <= 4){
y <- sprintf("%04s", char.time)
t <- paste(substr(y, 0, 2), substr(y, 3, 4), sep=":")
} else {
break()
}
return(t)
}
setnames(dt1, tolower(names(dt1)))
to.keep <- c("state", "evtype", "bgn_date", "bgn_time", "mag", "fatalities", "injuries", "propdmg", "propdmgexp", "cropdmg", "cropdmgexp")
dt1 <- dt1[, to.keep, with=FALSE] #new table with only selected columns
dt1[, bgn_date:=as.character(bgn_date)]
dt1[, bgn_time:=as.character(bgn_time)]
dt1[, date:=as.Date(bgn_date, format="%m/%d/%Y")]
dt1[, time:=unifTime(bgn_time), by=1:nrow(dt1)]
fatal <- dt1[, sum(fatalities), by=list(evtype, year(date))]
f1 <- fatal[, sum(V1), by=evtype] #summed by event type over all years
f1.max <- f1[which.max(f1$V1)] # which is most fatal?
f2 <- fatal[, .SD[which.max(V1)], by=year]
f2.max <- count(f2, evtype) # which is most fatal by year?
f2.an <- f2[which.max(V1)] # which year was most fatal?
f3 <- dt1[, sum(fatalities), by=year(date)]
injured <- dt1[, sum(injuries), by=list(evtype, year(date))]
i1 <- injured[, sum(V1), by=evtype] #summed by event type over all years
i1.max <- i1[which.max(f1$V1)]
i2 <- injured[, .SD[which.max(V1)], by=year]
i2.max <- count(i2, evtype)
f1$evtype <- factor(f1$evtype, levels = f1$evtype[order(-f1$V1)])
f2$evtype <- factor(f2$evtype, levels = f2$evtype[order(-f2$V1)])
g.f1 <- ggplot(f1[order(-f1$V1)][1:10], aes(x=evtype, y=V1))
g.f1 <- g.f1 + geom_bar(stat="identity", aes(fill=evtype)) +
theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)) +
xlab("event type") + ylab("deaths") +
scale_fill_brewer(palette="Paired") + guides(fill=FALSE) +
ggtitle("Total deaths by event type, 1950-2011")
g.f2 <- ggplot(f2, aes(x=year, y=V1))
g.f2 <- g.f2 + geom_bar(stat="identity", aes(fill=f2$evtype)) +
scale_fill_brewer(palette="Set1") + ylab("deaths") + xlab("year") +
ggtitle("deadliest event type by year") +
guides(fill=guide_legend(title=NULL))
g.f3 <- g.f2 + geom_bar(stat="identity", aes(fill=f2$evtype)) +
scale_fill_brewer(palette="Set1") + ylab("deaths") + xlab("year") +
ggtitle("deadliest event type by year") +
guides(fill=guide_legend(title=NULL)) +
geom_line(data=f3, aes(x=year, y=V1))
levels(dt1$cropdmgexp)
levels(dt1$propdmgexp)
class(dt1$propdmgexp[14])
ch <- "1"
?between
?dplyr::between
between(ch, "0", "8")
as.numeric(ch)
ch <- "k"
as.numeric(ch)
to.lower(levels(dt1$cropdmgexp))
tolower(levels(dt1$cropdmgexp))
ch
ch <- "1e3"
as.numeric(ch)
paste(e, 3)
paste("e", "3")
paste("e", "3", sep="")
paste("1e", "3", sep="")
as.numeric(paste("1e", "3", sep=""))
focConv <- function(exp.type){
exp.type <- to.lower(exp.type)
if(exp.type=="b") return(1e9)
if(exp.type=="m") return(1e6)
if(exp.type=="k") return(1e6)
if(exp.type=="?") return(1)
if(exp.type=="+") return(1)
if(exp.type=="-") return(1)
if(exp.type=="") return(1)
return(as.numeric(paste("1e", as.character(exp.type), sep="")))
}
dt2 <- dt1
dt2[, prop.mult:=focConv(propdmgexp), by=1:nrow(propdmgexp)]
names(dt2)
dim(dt2)
nrow(dt2$propdmgexp)
dt2[, prop.mult:=focConv(propdmgexp), by=1:nrow(dt2)]
focConv <- function(exp.type){
exp.type <- tolower(exp.type)
if(exp.type=="b") return(1e9)
if(exp.type=="m") return(1e6)
if(exp.type=="k") return(1e6)
if(exp.type=="?") return(1)
if(exp.type=="+") return(1)
if(exp.type=="-") return(1)
if(exp.type=="") return(1)
return(as.numeric(paste("1e", as.character(exp.type), sep="")))
}
dt2[, prop.mult:=focConv(propdmgexp), by=1:nrow(dt2)]
head(dt2$prop.mult)
sum(is.na(dt2$prop.mult))
dt2[is.na(prop.mult)]
focConv <- function(exp.type){
exp.type <- tolower(exp.type)
if(exp.type=="b") return(1e9)
if(exp.type=="m") return(1e6)
if(exp.type=="k") return(1e6)
if(exp.type=="h") return(1e3)
if(exp.type=="?") return(1)
if(exp.type=="+") return(1)
if(exp.type=="-") return(1)
if(exp.type=="") return(1)
return(as.numeric(paste("1e", as.character(exp.type), sep="")))
}
names(dt1)
dt1[,prop.mult:=NULL]
dt2 <- copy(dt1)
dt2[, prop.mult:=focConv(propdmgexp), by=1:nrow(dt2)]
dt2[, crop.mult:=focConv(cropdmgexp), by=1:nrow(dt2)]
dt2[, dmg.property:=propdmg*prop.mult]
dt2[, dmg.crops:=cropdmg*crop.mult]
head(dt2)
to.integer(dt2$dmg.property[1])
integer(dt2$dmg.property[1])
property <- dt2[, sum(dmg.property), by=list(evtype, year(date))]
croperty <- dt2[, sum(dmg.crops), by=list(evtype, year(date))]
head(property)
head(croperty)
property.ev <- property[, sum(V1), by=evtype]
croperty.ev <- croperty[, sum(V1), by=evtype]
head(property.ev)
property
property.ev
levels(property.ev$evtype)
dt1[, evtype:=tolower(evtype)]
dt2 <- copy(dt1)
dt2[, prop.mult:=focConv(propdmgexp), by=1:nrow(dt2)]
dt2[, crop.mult:=focConv(cropdmgexp), by=1:nrow(dt2)]
dt2[, dmg.property:=propdmg*prop.mult]
dt2[, dmg.crops:=cropdmg*crop.mult]
# overall
property <- dt2[, sum(dmg.property), by=list(evtype, year(date))]
croperty <- dt2[, sum(dmg.crops), by=list(evtype, year(date))]
property.ev <- property[, sum(V1), by=evtype]
croperty.ev <- croperty[, sum(V1), by=evtype]
property.ev[which.max(V1)]
property <- dt2[, sum(dmg.property, dmg.crops), by=list(evtype, year(date))]
head(property)
combined.max <- combined.ev[which.max(V1)]
combined.ev <- combined[, sum(V1), by=evtype]
combined <- dt2[, sum(dmg.property, dmg.crops), by=list(evtype, year(date))]
combined.ev <- combined[, sum(V1), by=evtype]
combined.max <- combined.ev[which.max(V1)]
combined.max
eval(combined.max$V1)
numeric(combined.max$V1)
combined.an <- combined[, sum(V1), by=year]
combined.an <- combined[, sum(V1), by=year]
combined.wan <- combined.an[which.max(V1)]
combined.wan
combined.ev[which.max(combined.an[which.max(V1)])]
plot(combined.ev)
head(combined.ev)
hist(combined.ev)
plot(combined.ev$evtype, combined.ev$V1)
